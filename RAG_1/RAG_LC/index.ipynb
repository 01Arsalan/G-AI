{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8819164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/base/Desktop/G-AI') # Adjust the path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae55e9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'RAG_1.RAG_LC.engine' from '/Users/base/Desktop/G-AI/RAG_1/RAG_LC/engine.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import RAG_1.RAG_LC.engine as engine          \n",
    "importlib.reload(engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4313dfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL RESPONSE:\n",
      " [LLM_ERROR] 'ChatOpenAI' object is not callable\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from  RAG_1.RAG_LC.engine import LangChainAiAssistant\n",
    "from RAG_1.RAG.tools import search_internet, search_doc\n",
    "\n",
    "# ensure OPENAI_API_KEY in env or pass into constructor\n",
    "assistant = LangChainAiAssistant(openai_api_key=\"add_new_key")\n",
    "\n",
    "\n",
    "assistant.register_tool(\"search_internet\", search_internet)\n",
    "assistant.register_tool(\"search_doc\", search_doc)\n",
    "\n",
    "async def run_demo():\n",
    "    res = await assistant.ask(\"I dreamed I chased a fox across a snowy field; what does it mean?\")\n",
    "    print(\"\\nFINAL RESPONSE:\\n\", res)\n",
    "\n",
    "# in a notebook cell\n",
    "import nest_asyncio, asyncio\n",
    "nest_asyncio.apply()\n",
    "asyncio.run(run_demo())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9506a029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL RESPONSE:\n",
      " ChatCompletion(id='chatcmpl-7299501d-9353-468b-a510-5e47877dd041', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='To better understand the symbolism of the fox and the snowy field, I\\'ll search the internet for information on these symbols.\\n\\n{\\n\"tool\": \"search_internet\",\\n\"query\": \"fox symbolism in dreams\"\\n}\\n\\nThe snowy field may also hold some significance, so I\\'ll search the internet for information on this as well.\\n\\n{\\n\"tool\": \"search_internet\",\\n\"query\": \"snowy field symbolism in dreams\"\\n}\\n\\nPlease wait for the results.', role='assistant', annotations=None, executed_tools=None, function_call=None, reasoning=None, tool_calls=None))], created=1764225250, model='llama-3.1-8b-instant', object='chat.completion', system_fingerprint='fp_ff2b098aaf', usage=CompletionUsage(completion_tokens=93, prompt_tokens=583, total_tokens=676, completion_time=0.179364221, prompt_time=0.039125576, queue_time=0.060026844, total_time=0.218489797), usage_breakdown=None, x_groq={'id': 'req_01kb209x6bep2tsj4pf4c8egtv', 'seed': 984795350}, service_tier='on_demand')\n"
     ]
    }
   ],
   "source": [
    "# ---------- USAGE EXAMPLE ----------\n",
    "\n",
    "from RAG_1.RAG.tools import search_internet, search_doc\n",
    "from  RAG_1.RAG_LC.engine import LangChainAiAssistant\n",
    "import asyncio\n",
    "\n",
    "# Provide GROQ_API_KEY in environment if you have one. Groq client can also work without required env var in some setups.\n",
    "groq_key = \"add_new_key"\n",
    "assistant = LangChainAiAssistant(groq_api_key=groq_key, groq_model=\"llama-3.1-8b-instant\")\n",
    "\n",
    "\n",
    "assistant.register_tool(\"search_internet\", search_internet)\n",
    "assistant.register_tool(\"search_doc\", search_doc)\n",
    "\n",
    "async def run_demo():\n",
    "    res = await assistant.ask(\"I dreamed I chased a fox across a snowy field; what does it mean?\")\n",
    "    print(\"\\nFINAL RESPONSE:\\n\", res)\n",
    "\n",
    "await run_demo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f7596d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (G-AI)",
   "language": "python",
   "name": "g-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
