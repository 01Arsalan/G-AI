{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77e4eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/base/Desktop/G-AI/CONCEPTS/MCP') # Adjust the path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ae61493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/base/Desktop/G-AI/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain.agents import create_agent\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff307733",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#test to check if sub-process server is working\n",
    "# !python /Users/base/Desktop/G-AI/CONCEPTS/MCP/mcp_server.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee97f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run the server first in separate terminal: python mcp_server_stdio.py\n",
    "#connects tot the MCP, keeps it as sub-process\n",
    "\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"math\": {\n",
    "            \"transport\": \"stdio\",\n",
    "            \"command\": sys.executable,         # e.g. 'python'\n",
    "            \"args\": [\"/Users/base/Desktop/G-AI/CONCEPTS/MCP/mcp_server_stdio.py\"],        \n",
    "        }\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14a788ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='add', description='Adds two integers together.\\nargs:\\n    a: The first integer.\\n    b: The second integer.\\nreturns:\\n    The sum of the two integers.', args_schema={'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}, metadata={'_meta': {'_fastmcp': {'tags': []}}}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x108075080>),\n",
       " StructuredTool(name='multiply_tool', description='Multiplies two integers together.', args_schema={'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}, metadata={'_meta': {'_fastmcp': {'tags': []}}}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x1080753a0>)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = await client.get_tools()\n",
    "tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4792d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groq model\n",
    "from langchain_groq import ChatGroq\n",
    "GROQ_MODEL = \"llama-3.1-8b-instant\"\n",
    "\n",
    "# Initialize Groq-backed LLM for LangChain\n",
    "model = ChatGroq(\n",
    "    model=GROQ_MODEL,\n",
    "    temperature=0.1,\n",
    "    max_tokens=1000,\n",
    "    timeout=30\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fc29741",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model,  # or your preferred model identifier\n",
    "    tools,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a231154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='What is (3 + 5) * 12 using your tools?', additional_kwargs={}, response_metadata={}, id='a3c731a9-4447-4eb3-bff9-87b53b46c349'),\n",
      "              AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'aej4s5xz4', 'function': {'arguments': '{\"a\":3,\"b\":5}', 'name': 'add'}, 'type': 'function'}, {'id': '05chg62mk', 'function': {'arguments': '{\"a\":8,\"b\":12}', 'name': 'multiply_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 343, 'total_tokens': 380, 'completion_time': 0.052517127, 'prompt_time': 0.020354568, 'queue_time': 0.049278502, 'total_time': 0.072871695}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--da578abb-c6e7-4a1d-a5bd-9a5c90bdb4bb-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'aej4s5xz4', 'type': 'tool_call'}, {'name': 'multiply_tool', 'args': {'a': 8, 'b': 12}, 'id': '05chg62mk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 343, 'output_tokens': 37, 'total_tokens': 380}),\n",
      "              ToolMessage(content='8', name='add', id='66d33de0-a886-48df-8fc2-2da621af07e6', tool_call_id='aej4s5xz4'),\n",
      "              ToolMessage(content='96', name='multiply_tool', id='81d94bf2-4446-498a-b27a-6eacf87657c0', tool_call_id='05chg62mk'),\n",
      "              AIMessage(content='The result of (3 + 5) * 12 is 96.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 398, 'total_tokens': 415, 'completion_time': 0.020012517, 'prompt_time': 0.034398594, 'queue_time': 0.050574275, 'total_time': 0.054411111}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--9b05032a-f7be-4b1c-95d9-39efbe4d391e-0', usage_metadata={'input_tokens': 398, 'output_tokens': 17, 'total_tokens': 415})]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "result = await agent.ainvoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is (3 + 5) * 12 using your tools?\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "pprint(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d48c971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (G-AI)",
   "language": "python",
   "name": "g-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
