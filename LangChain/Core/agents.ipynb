{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e10790e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/base/Desktop/G-AI') # Adjust the path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ccee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from RAG_1.RAG.tools import search_internet\n",
    "\n",
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for information on internet.\"\"\"\n",
    "    result = search_internet(query=query)\n",
    "    return f\"Results for: {query}:\\n\\n {result}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3d55fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "# Groq model\n",
    "GROQ_MODEL = \"llama-3.1-8b-instant\"\n",
    "\n",
    "# Initialize Groq-backed LLM for LangChain\n",
    "model = ChatGroq(\n",
    "    model=GROQ_MODEL,\n",
    "    temperature=0.1,\n",
    "    max_tokens=1000,\n",
    "    timeout=30\n",
    ")\n",
    "\n",
    "# Build agent with Groq model + LangChain tools\n",
    "agent = create_agent(model, tools=[search])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dcfbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What's the weather in San Francisco?\"}]}\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea90422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "\n",
    "\n",
    "basic_model = ChatGroq(\n",
    "    model=GROQ_MODEL,\n",
    "    temperature=0.1,\n",
    "    max_tokens=1000,\n",
    "    timeout=30\n",
    ")\n",
    "advanced_model = ChatGroq(\n",
    "    model=GROQ_MODEL,\n",
    "    temperature=0.1,\n",
    "    max_tokens=1000,\n",
    "    timeout=30\n",
    ")\n",
    "\n",
    "@wrap_model_call\n",
    "def dynamic_model_selection(request: ModelRequest, handler) -> ModelResponse:\n",
    "    \"\"\"Choose model based on conversation complexity.\"\"\"\n",
    "    message_count = len(request.state[\"messages\"])\n",
    "\n",
    "    if message_count > 10:\n",
    "        # Use an advanced model for longer conversations\n",
    "        model = advanced_model\n",
    "    else:\n",
    "        model = basic_model\n",
    "\n",
    "    return handler(request.override(model=model))\n",
    "\n",
    "agent = create_agent(\n",
    "    model=basic_model,  # Default model\n",
    "    tools=[],\n",
    "    middleware=[dynamic_model_selection]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77203218",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"testing middleware\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320e4acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "def read_email_tool(email_id: str) -> str:\n",
    "    \"\"\"Mock function to read an email by its ID.\"\"\"\n",
    "    return f\"Email content for ID: {email_id}\"\n",
    "\n",
    "def send_email_tool(recipient: str, subject: str, body: str) -> str:\n",
    "    \"\"\"Mock function to send an email.\"\"\"\n",
    "    return f\"Email sent to {recipient} with subject '{subject}'\"\n",
    "\n",
    "\n",
    "# Groq model\n",
    "GROQ_MODEL = \"llama-3.1-8b-instant\"\n",
    "\n",
    "# Initialize Groq-backed LLM for LangChain\n",
    "model = ChatGroq(\n",
    "    model=GROQ_MODEL,\n",
    "    temperature=0.1,\n",
    "    max_tokens=1000,\n",
    "    timeout=30\n",
    ")\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[read_email_tool, send_email_tool],\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[\n",
    "        HumanInTheLoopMiddleware(\n",
    "            interrupt_on={\n",
    "                \"send_email_tool\": {\n",
    "                    \"allowed_decisions\": [\"approve\", \"edit\", \"reject\"],\n",
    "                },\n",
    "                \"read_email_tool\": False,\n",
    "            }\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae607e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "agent.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"Please read the email with ID 12345 and send a reply.[mock test call the avl tools]\"}\n",
    "    ]\n",
    "}, config=config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b4a82c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dd1a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4d82005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANGCHAIN_TRACING_V2 = true\n",
      "LANGCHAIN_API_KEY = add_new_key\n",
      "LANGCHAIN_PROJECT = FirstLangChainProject\n",
      "LANGCHAIN_ENDPOINT = None\n"
     ]
    }
   ],
   "source": [
    "# Human in the loop\n",
    "\n",
    "import os\n",
    "\n",
    "for k in [\"LANGCHAIN_TRACING_V2\", \"LANGCHAIN_API_KEY\", \"LANGCHAIN_PROJECT\", \"LANGCHAIN_ENDPOINT\"]:\n",
    "    print(k, \"=\", os.getenv(k))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0483ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3fa70d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "from langsmith import traceable\n",
    "\n",
    "@traceable(name=\"notebook-test-trace\")\n",
    "def foo(x):\n",
    "    return x * 2\n",
    "\n",
    "print(foo(21))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a15a328e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Client.list_projects at 0x10d9b0970>\n"
     ]
    }
   ],
   "source": [
    "print(client.list_projects())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7abf8518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/base/Desktop/G-AI/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import HumanInTheLoopMiddleware, LLMToolEmulator\n",
    "from langgraph.checkpoint.memory import InMemorySaver \n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def write_file_tool(file_path: str, content: str) -> str:\n",
    "    \"\"\"Mock function to write content to a file.\"\"\"\n",
    "    return f\"Written to {file_path}\"\n",
    "@tool\n",
    "def execute_sql_tool(query: str) -> str:\n",
    "    \"\"\"Mock function to execute an SQL query.\"\"\"\n",
    "    return f\"Executed SQL query: {query}\"\n",
    "@tool\n",
    "def read_data_tool(data_id: str) -> str:\n",
    "    \"\"\"Mock function to read data by its ID.\"\"\"\n",
    "    return f\"Data for ID: {data_id}\"\n",
    "\n",
    "\n",
    "# Groq model\n",
    "GROQ_MODEL = \"llama-3.1-8b-instant\"\n",
    "\n",
    "# Initialize Groq-backed LLM for LangChain\n",
    "model = ChatGroq(\n",
    "    model=GROQ_MODEL,\n",
    "    temperature=0.1,\n",
    "    max_tokens=1000,\n",
    "    timeout=30\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[write_file_tool, execute_sql_tool, read_data_tool],\n",
    "    middleware=[\n",
    "        LLMToolEmulator(model=model,tools=[\"write_file_tool\",\"execute_sql_tool\",\"read_data_tool\"]),  # Emulate tool calls for testing\n",
    "        HumanInTheLoopMiddleware( \n",
    "            interrupt_on={\n",
    "                \"write_file_tool\": True,  # All decisions (approve, edit, reject) allowed\n",
    "                \"execute_sql_tool\": {\"allowed_decisions\": [\"approve\", \"reject\"]},  # No editing allowed\n",
    "                # Safe operation, no approval needed\n",
    "                \"read_data_tool\": False,\n",
    "            },\n",
    "            # Prefix for interrupt messages - combined with tool name and args to form the full message\n",
    "            # e.g., \"Tool execution pending approval: execute_sql with query='DELETE FROM...'\"\n",
    "            # Individual tools can override this by specifying a \"description\" in their interrupt config\n",
    "            description_prefix=\"Tool execution pending approval\",\n",
    "        ),\n",
    "    ],\n",
    "    # Human-in-the-loop requires checkpointing to handle interrupts.\n",
    "    # In production, use a persistent checkpointer like AsyncPostgresSaver.\n",
    "    checkpointer=InMemorySaver(),  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7404e9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Interrupt(value={'action_requests': [{'name': 'execute_sql_tool', 'args': {'query': 'DELETE FROM records WHERE created_at < DATE_SUB(CURRENT_DATE, INTERVAL 30 DAY)'}, 'description': \"Tool execution pending approval\\n\\nTool: execute_sql_tool\\nArgs: {'query': 'DELETE FROM records WHERE created_at < DATE_SUB(CURRENT_DATE, INTERVAL 30 DAY)'}\"}], 'review_configs': [{'action_name': 'execute_sql_tool', 'allowed_decisions': ['approve', 'reject']}]}, id='965387824a58f3dcd3adf30581e27d19')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Delete old records from the database', additional_kwargs={}, response_metadata={}, id='e7af938c-d365-4419-b094-c1667f9db62f'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'bd3g9qnq9', 'function': {'arguments': '{\"query\":\"DELETE FROM records WHERE created_at \\\\u003c DATE_SUB(CURRENT_DATE, INTERVAL 30 DAY)\"}', 'name': 'execute_sql_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 348, 'total_tokens': 381, 'completion_time': 0.047241473, 'prompt_time': 0.041788036, 'queue_time': 0.060652954, 'total_time': 0.089029509}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--628acd74-eed4-40c4-b580-df7202c68c18-0', tool_calls=[{'name': 'execute_sql_tool', 'args': {'query': 'DELETE FROM records WHERE created_at < DATE_SUB(CURRENT_DATE, INTERVAL 30 DAY)'}, 'id': 'bd3g9qnq9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 348, 'output_tokens': 33, 'total_tokens': 381}),\n",
       "  ToolMessage(content='{\\n  \"affected_rows\": 150,\\n  \"query\": \"DELETE FROM records WHERE created_at < DATE_SUB(CURRENT_DATE, INTERVAL 30 DAY)\",\\n  \"status\": \"success\",\\n  \"message\": \"Query executed successfully\",\\n  \"execution_time\": 0.0123,\\n  \"rows_affected\": 150,\\n  \"rows_returned\": 0,\\n  \"warnings\": []\\n}', name='execute_sql_tool', id='e9f4d6c7-64a4-45fe-ae44-71671178b860', tool_call_id='bd3g9qnq9'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'yn6d6j3rg', 'function': {'arguments': '{\"content\":\"Records deleted successfully\",\"file_path\":\"/logs/records_deleted.log\"}', 'name': 'write_file_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 473, 'total_tokens': 502, 'completion_time': 0.045212102, 'prompt_time': 0.034318458, 'queue_time': 0.051092281, 'total_time': 0.07953056}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--89d804cb-18b2-4674-b324-7fcbbd49dbdd-0', tool_calls=[{'name': 'write_file_tool', 'args': {'content': 'Records deleted successfully', 'file_path': '/logs/records_deleted.log'}, 'id': 'yn6d6j3rg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 473, 'output_tokens': 29, 'total_tokens': 502})],\n",
       " '__interrupt__': [Interrupt(value={'action_requests': [{'name': 'write_file_tool', 'args': {'content': 'Records deleted successfully', 'file_path': '/logs/records_deleted.log'}, 'description': \"Tool execution pending approval\\n\\nTool: write_file_tool\\nArgs: {'content': 'Records deleted successfully', 'file_path': '/logs/records_deleted.log'}\"}], 'review_configs': [{'action_name': 'write_file_tool', 'allowed_decisions': ['approve', 'edit', 'reject']}]}, id='90a76599c1edc0ed14cdffeb830ca44a')]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.types import Command\n",
    "\n",
    "# Human-in-the-loop leverages LangGraph's persistence layer.\n",
    "# You must provide a thread ID to associate the execution with a conversation thread,\n",
    "# so the conversation can be paused and resumed (as is needed for human review).\n",
    "config = {\"configurable\": {\"thread_id\": \"some_id\"}} \n",
    "# Run the graph until the interrupt is hit.\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Delete old records from the database\",\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    config=config \n",
    ")\n",
    "\n",
    "# The interrupt contains the full HITL request with action_requests and review_configs\n",
    "print(result['__interrupt__'])\n",
    "# > [\n",
    "# >    Interrupt(\n",
    "# >       value={\n",
    "# >          'action_requests': [\n",
    "# >             {\n",
    "# >                'name': 'execute_sql',\n",
    "# >                'arguments': {'query': 'DELETE FROM records WHERE created_at < NOW() - INTERVAL \\'30 days\\';'},\n",
    "# >                'description': 'Tool execution pending approval\\n\\nTool: execute_sql\\nArgs: {...}'\n",
    "# >             }\n",
    "# >          ],\n",
    "# >          'review_configs': [\n",
    "# >             {\n",
    "# >                'action_name': 'execute_sql',\n",
    "# >                'allowed_decisions': ['approve', 'reject']\n",
    "# >             }\n",
    "# >          ]\n",
    "# >       }\n",
    "# >    )\n",
    "# > ]\n",
    "\n",
    "\n",
    "# Resume with approval decision\n",
    "agent.invoke(\n",
    "    Command( \n",
    "        resume={\"decisions\": [{\"type\": \"approve\"}]}  # or \"edit\", \"reject\"\n",
    "    ), \n",
    "    config=config # Same thread ID to resume the paused conversation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8753c680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resume with approval decision\n",
    "agent.invoke(\n",
    "    Command( \n",
    "        resume={\"decisions\": [{\"type\": \"approve\"}]}  # or \"edit\", \"reject\"\n",
    "    ), \n",
    "    config=config # Same thread ID to resume the paused conversation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3dbe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec96ddff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (G-AI)",
   "language": "python",
   "name": "g-ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
